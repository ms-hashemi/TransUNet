/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Namespace(dataset='Degradation', img_size=[64, 64, 64], vit_patches_size=[8, 8, 8], vit_name='ViT-B_16', pretrained_net_path=False, is_encoder_pretrained=False, deterministic=1, max_epochs=4, batch_size=48, base_lr=0.01, seed=1234, gpu=4, world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', local_rank=-1, num_classes=2, root_path='/work/sheidaei/mhashemi/data/deg', list_dir='./lists/lists_Degradation', exp='TVD_Degradation[64, 64, 64]', distributed=False)
169 iterations per epoch. 676 max iterations 
  0%|                                           | 0/4 [00:00<?, ?it/s]iteration      1: loss: 0.553647, loss_ce: 0.693176, loss_dice: 0.414118
iteration      2: loss: 0.464953, loss_ce: 0.556396, loss_dice: 0.373511
iteration      3: loss: 0.424109, loss_ce: 0.478301, loss_dice: 0.369917
iteration      4: loss: 0.421491, loss_ce: 0.465042, loss_dice: 0.377940
iteration      5: loss: 0.412979, loss_ce: 0.446637, loss_dice: 0.379322
iteration      6: loss: 0.395026, loss_ce: 0.430874, loss_dice: 0.359178
iteration      7: loss: 0.387833, loss_ce: 0.433635, loss_dice: 0.342031
iteration      8: loss: 0.380627, loss_ce: 0.440984, loss_dice: 0.320270
iteration      9: loss: 0.363582, loss_ce: 0.417003, loss_dice: 0.310162
iteration     10: loss: 0.379473, loss_ce: 0.452202, loss_dice: 0.306743
iteration     11: loss: 0.375251, loss_ce: 0.445558, loss_dice: 0.304943
iteration     12: loss: 0.371123, loss_ce: 0.437587, loss_dice: 0.304659
iteration     13: loss: 0.365530, loss_ce: 0.423396, loss_dice: 0.307664
iteration     14: loss: 0.371711, loss_ce: 0.431024, loss_dice: 0.312399
iteration     15: loss: 0.359232, loss_ce: 0.404820, loss_dice: 0.313643
iteration     16: loss: 0.363331, loss_ce: 0.412607, loss_dice: 0.314056
iteration     17: loss: 0.361184, loss_ce: 0.409825, loss_dice: 0.312544
iteration     18: loss: 0.349101, loss_ce: 0.391378, loss_dice: 0.306824
iteration     19: loss: 0.357181, loss_ce: 0.406086, loss_dice: 0.308277
iteration     20: loss: 0.353964, loss_ce: 0.400699, loss_dice: 0.307229
iteration     21: loss: 0.360662, loss_ce: 0.417389, loss_dice: 0.303935
iteration     22: loss: 0.369408, loss_ce: 0.434358, loss_dice: 0.304459
iteration     23: loss: 0.354274, loss_ce: 0.410791, loss_dice: 0.297757
iteration     24: loss: 0.344265, loss_ce: 0.393013, loss_dice: 0.295517
iteration     25: loss: 0.356328, loss_ce: 0.416635, loss_dice: 0.296022
iteration     26: loss: 0.358097, loss_ce: 0.419065, loss_dice: 0.297129
iteration     27: loss: 0.351427, loss_ce: 0.407930, loss_dice: 0.294925
iteration     28: loss: 0.348547, loss_ce: 0.403896, loss_dice: 0.293197
iteration     29: loss: 0.347348, loss_ce: 0.404515, loss_dice: 0.290182
iteration     30: loss: 0.351337, loss_ce: 0.407810, loss_dice: 0.294863
iteration     31: loss: 0.354656, loss_ce: 0.411358, loss_dice: 0.297955
iteration     32: loss: 0.350006, loss_ce: 0.404918, loss_dice: 0.295094
iteration     33: loss: 0.343602, loss_ce: 0.392182, loss_dice: 0.295022
iteration     34: loss: 0.345131, loss_ce: 0.394652, loss_dice: 0.295611
iteration     35: loss: 0.353246, loss_ce: 0.407422, loss_dice: 0.299070
iteration     36: loss: 0.355561, loss_ce: 0.413261, loss_dice: 0.297862
iteration     37: loss: 0.338414, loss_ce: 0.387585, loss_dice: 0.289242
iteration     38: loss: 0.351951, loss_ce: 0.409235, loss_dice: 0.294666
iteration     39: loss: 0.353715, loss_ce: 0.411991, loss_dice: 0.295439
iteration     40: loss: 0.347849, loss_ce: 0.404117, loss_dice: 0.291581
iteration     41: loss: 0.352632, loss_ce: 0.406221, loss_dice: 0.299044
iteration     42: loss: 0.345805, loss_ce: 0.397768, loss_dice: 0.293843
iteration     43: loss: 0.361945, loss_ce: 0.423320, loss_dice: 0.300570
iteration     44: loss: 0.352764, loss_ce: 0.408686, loss_dice: 0.296842
iteration     45: loss: 0.345550, loss_ce: 0.393755, loss_dice: 0.297345
iteration     46: loss: 0.358938, loss_ce: 0.419922, loss_dice: 0.297955
iteration     47: loss: 0.346449, loss_ce: 0.397917, loss_dice: 0.294982
iteration     48: loss: 0.350789, loss_ce: 0.405534, loss_dice: 0.296044
iteration     49: loss: 0.351786, loss_ce: 0.410613, loss_dice: 0.292960
iteration     50: loss: 0.340668, loss_ce: 0.391790, loss_dice: 0.289547
iteration     51: loss: 0.346711, loss_ce: 0.399545, loss_dice: 0.293876
iteration     52: loss: 0.340376, loss_ce: 0.390974, loss_dice: 0.289779
iteration     53: loss: 0.349923, loss_ce: 0.403962, loss_dice: 0.295885
iteration     54: loss: 0.355983, loss_ce: 0.413800, loss_dice: 0.298165
iteration     55: loss: 0.356262, loss_ce: 0.415939, loss_dice: 0.296586
iteration     56: loss: 0.335845, loss_ce: 0.379726, loss_dice: 0.291964
iteration     57: loss: 0.338725, loss_ce: 0.386908, loss_dice: 0.290542
iteration     58: loss: 0.355489, loss_ce: 0.414295, loss_dice: 0.296682
iteration     59: loss: 0.358901, loss_ce: 0.422517, loss_dice: 0.295285
iteration     60: loss: 0.342939, loss_ce: 0.394281, loss_dice: 0.291598
iteration     61: loss: 0.346632, loss_ce: 0.403147, loss_dice: 0.290117
iteration     62: loss: 0.334804, loss_ce: 0.381221, loss_dice: 0.288387
iteration     63: loss: 0.342030, loss_ce: 0.392265, loss_dice: 0.291794
iteration     64: loss: 0.347432, loss_ce: 0.400862, loss_dice: 0.294003
iteration     65: loss: 0.352107, loss_ce: 0.408703, loss_dice: 0.295511
iteration     66: loss: 0.351760, loss_ce: 0.406953, loss_dice: 0.296567
iteration     67: loss: 0.339361, loss_ce: 0.386767, loss_dice: 0.291955
iteration     68: loss: 0.345300, loss_ce: 0.399697, loss_dice: 0.290902
iteration     69: loss: 0.349270, loss_ce: 0.405280, loss_dice: 0.293261
iteration     70: loss: 0.328450, loss_ce: 0.367860, loss_dice: 0.289040
iteration     71: loss: 0.343801, loss_ce: 0.396148, loss_dice: 0.291455
iteration     72: loss: 0.346915, loss_ce: 0.404266, loss_dice: 0.289564
iteration     73: loss: 0.335694, loss_ce: 0.381793, loss_dice: 0.289595
iteration     74: loss: 0.339340, loss_ce: 0.387456, loss_dice: 0.291224
iteration     75: loss: 0.341140, loss_ce: 0.393879, loss_dice: 0.288402
iteration     76: loss: 0.347582, loss_ce: 0.406306, loss_dice: 0.288858
iteration     77: loss: 0.341480, loss_ce: 0.393094, loss_dice: 0.289866
iteration     78: loss: 0.341653, loss_ce: 0.396925, loss_dice: 0.286381
iteration     79: loss: 0.328524, loss_ce: 0.372290, loss_dice: 0.284759
iteration     80: loss: 0.336229, loss_ce: 0.384883, loss_dice: 0.287576
iteration     81: loss: 0.329112, loss_ce: 0.368976, loss_dice: 0.289249
iteration     82: loss: 0.328209, loss_ce: 0.368653, loss_dice: 0.287765
iteration     83: loss: 0.336592, loss_ce: 0.382157, loss_dice: 0.291026
iteration     84: loss: 0.346520, loss_ce: 0.399039, loss_dice: 0.294001
iteration     85: loss: 0.341907, loss_ce: 0.395970, loss_dice: 0.287844
iteration     86: loss: 0.337853, loss_ce: 0.388875, loss_dice: 0.286830
iteration     87: loss: 0.328216, loss_ce: 0.374599, loss_dice: 0.281833
iteration     88: loss: 0.329916, loss_ce: 0.376621, loss_dice: 0.283211
iteration     89: loss: 0.327968, loss_ce: 0.371735, loss_dice: 0.284202
iteration     90: loss: 0.342492, loss_ce: 0.396243, loss_dice: 0.288741
iteration     91: loss: 0.355080, loss_ce: 0.411785, loss_dice: 0.298376
iteration     92: loss: 0.340957, loss_ce: 0.389664, loss_dice: 0.292251
iteration     93: loss: 0.329465, loss_ce: 0.371480, loss_dice: 0.287451
iteration     94: loss: 0.348385, loss_ce: 0.407380, loss_dice: 0.289389
iteration     95: loss: 0.337273, loss_ce: 0.389048, loss_dice: 0.285499
iteration     96: loss: 0.324209, loss_ce: 0.368431, loss_dice: 0.279988
iteration     97: loss: 0.334791, loss_ce: 0.385226, loss_dice: 0.284355
iteration     98: loss: 0.338674, loss_ce: 0.394235, loss_dice: 0.283112
iteration     99: loss: 0.337196, loss_ce: 0.390042, loss_dice: 0.284350
iteration    100: loss: 0.323847, loss_ce: 0.365160, loss_dice: 0.282534
iteration    101: loss: 0.348019, loss_ce: 0.411138, loss_dice: 0.284900
iteration    102: loss: 0.348026, loss_ce: 0.406501, loss_dice: 0.289552
iteration    103: loss: 0.321088, loss_ce: 0.362598, loss_dice: 0.279578
iteration    104: loss: 0.339794, loss_ce: 0.396839, loss_dice: 0.282748
iteration    105: loss: 0.348643, loss_ce: 0.411552, loss_dice: 0.285734
iteration    106: loss: 0.336600, loss_ce: 0.387984, loss_dice: 0.285216
iteration    107: loss: 0.328822, loss_ce: 0.375660, loss_dice: 0.281984
iteration    108: loss: 0.338514, loss_ce: 0.387976, loss_dice: 0.289052
iteration    109: loss: 0.334145, loss_ce: 0.384906, loss_dice: 0.283384
iteration    110: loss: 0.337889, loss_ce: 0.392574, loss_dice: 0.283204
iteration    111: loss: 0.332460, loss_ce: 0.382237, loss_dice: 0.282682
iteration    112: loss: 0.348183, loss_ce: 0.413686, loss_dice: 0.282681
iteration    113: loss: 0.347724, loss_ce: 0.408995, loss_dice: 0.286452
iteration    114: loss: 0.332031, loss_ce: 0.378956, loss_dice: 0.285106
iteration    115: loss: 0.330446, loss_ce: 0.381423, loss_dice: 0.279469
iteration    116: loss: 0.333464, loss_ce: 0.389323, loss_dice: 0.277605
iteration    117: loss: 0.330674, loss_ce: 0.377696, loss_dice: 0.283652
iteration    118: loss: 0.334487, loss_ce: 0.385777, loss_dice: 0.283197
iteration    119: loss: 0.338766, loss_ce: 0.398973, loss_dice: 0.278558
iteration    120: loss: 0.342457, loss_ce: 0.403230, loss_dice: 0.281683
iteration    121: loss: 0.332562, loss_ce: 0.388011, loss_dice: 0.277113
iteration    122: loss: 0.352590, loss_ce: 0.419389, loss_dice: 0.285791
iteration    123: loss: 0.337510, loss_ce: 0.395942, loss_dice: 0.279078
iteration    124: loss: 0.325454, loss_ce: 0.376891, loss_dice: 0.274016
iteration    125: loss: 0.330807, loss_ce: 0.383539, loss_dice: 0.278074
iteration    126: loss: 0.330060, loss_ce: 0.383929, loss_dice: 0.276190
iteration    127: loss: 0.343159, loss_ce: 0.402511, loss_dice: 0.283808
iteration    128: loss: 0.320428, loss_ce: 0.363563, loss_dice: 0.277294
iteration    129: loss: 0.334831, loss_ce: 0.391887, loss_dice: 0.277775
iteration    130: loss: 0.338878, loss_ce: 0.395177, loss_dice: 0.282578
iteration    131: loss: 0.347229, loss_ce: 0.411679, loss_dice: 0.282779
iteration    132: loss: 0.323913, loss_ce: 0.371784, loss_dice: 0.276042
iteration    133: loss: 0.338113, loss_ce: 0.390074, loss_dice: 0.286152
iteration    134: loss: 0.324076, loss_ce: 0.370237, loss_dice: 0.277915
iteration    135: loss: 0.330466, loss_ce: 0.383190, loss_dice: 0.277741
iteration    136: loss: 0.337476, loss_ce: 0.391135, loss_dice: 0.283818
iteration    137: loss: 0.333085, loss_ce: 0.381190, loss_dice: 0.284980
iteration    138: loss: 0.336848, loss_ce: 0.393327, loss_dice: 0.280370
iteration    139: loss: 0.327318, loss_ce: 0.378974, loss_dice: 0.275663
iteration    140: loss: 0.335947, loss_ce: 0.392935, loss_dice: 0.278958
iteration    141: loss: 0.346346, loss_ce: 0.410046, loss_dice: 0.282646
iteration    142: loss: 0.320229, loss_ce: 0.365871, loss_dice: 0.274588
iteration    143: loss: 0.337307, loss_ce: 0.392558, loss_dice: 0.282056
iteration    144: loss: 0.336535, loss_ce: 0.393827, loss_dice: 0.279242
iteration    145: loss: 0.333495, loss_ce: 0.389731, loss_dice: 0.277259
iteration    146: loss: 0.338036, loss_ce: 0.402031, loss_dice: 0.274040
iteration    147: loss: 0.326689, loss_ce: 0.378475, loss_dice: 0.274903
iteration    148: loss: 0.321546, loss_ce: 0.370918, loss_dice: 0.272174
iteration    149: loss: 0.331641, loss_ce: 0.384136, loss_dice: 0.279146
iteration    150: loss: 0.343103, loss_ce: 0.405636, loss_dice: 0.280569
iteration    151: loss: 0.335936, loss_ce: 0.394154, loss_dice: 0.277718
iteration    152: loss: 0.330207, loss_ce: 0.384673, loss_dice: 0.275742
iteration    153: loss: 0.341156, loss_ce: 0.399040, loss_dice: 0.283273
iteration    154: loss: 0.336387, loss_ce: 0.397607, loss_dice: 0.275167
iteration    155: loss: 0.336715, loss_ce: 0.398439, loss_dice: 0.274990
iteration    156: loss: 0.329036, loss_ce: 0.384270, loss_dice: 0.273803
iteration    157: loss: 0.333518, loss_ce: 0.389037, loss_dice: 0.278000
iteration    158: loss: 0.319997, loss_ce: 0.366473, loss_dice: 0.273522
iteration    159: loss: 0.325834, loss_ce: 0.379323, loss_dice: 0.272344
iteration    160: loss: 0.324738, loss_ce: 0.374713, loss_dice: 0.274762
iteration    161: loss: 0.322150, loss_ce: 0.373159, loss_dice: 0.271141
iteration    162: loss: 0.315322, loss_ce: 0.367534, loss_dice: 0.263110
iteration    163: loss: 0.345379, loss_ce: 0.407203, loss_dice: 0.283554
iteration    164: loss: 0.332812, loss_ce: 0.389364, loss_dice: 0.276260
iteration    165: loss: 0.340229, loss_ce: 0.398560, loss_dice: 0.281899
iteration    166: loss: 0.325902, loss_ce: 0.373028, loss_dice: 0.278775
iteration    167: loss: 0.335545, loss_ce: 0.391098, loss_dice: 0.279992
iteration    168: loss: 0.333303, loss_ce: 0.386436, loss_dice: 0.280170
iteration    169: loss: 0.328966, loss_ce: 0.378469, loss_dice: 0.279462
save model to ../model/TVD_Degradation[64, 64, 64]/TVD_ViT-B_16_vitpatch[8, 8, 8]_epo4_bs48_lr0.01_seed1234/epoch_0.pth
 25%|███████▎                     | 1/4 [1:11:28<3:34:24, 4288.26s/it]iteration    170: loss: 0.326614, loss_ce: 0.379204, loss_dice: 0.274025
iteration    171: loss: 0.326019, loss_ce: 0.381224, loss_dice: 0.270813
iteration    172: loss: 0.326707, loss_ce: 0.380417, loss_dice: 0.272997
iteration    173: loss: 0.333649, loss_ce: 0.393113, loss_dice: 0.274185
iteration    174: loss: 0.325106, loss_ce: 0.378340, loss_dice: 0.271872
iteration    175: loss: 0.330427, loss_ce: 0.386239, loss_dice: 0.274615
iteration    176: loss: 0.337784, loss_ce: 0.396153, loss_dice: 0.279415
iteration    177: loss: 0.329592, loss_ce: 0.382696, loss_dice: 0.276487
iteration    178: loss: 0.332586, loss_ce: 0.391468, loss_dice: 0.273705
iteration    179: loss: 0.324212, loss_ce: 0.374761, loss_dice: 0.273663
iteration    180: loss: 0.343851, loss_ce: 0.404816, loss_dice: 0.282885
iteration    181: loss: 0.329378, loss_ce: 0.388252, loss_dice: 0.270504
iteration    182: loss: 0.322236, loss_ce: 0.372285, loss_dice: 0.272186
iteration    183: loss: 0.326615, loss_ce: 0.378451, loss_dice: 0.274779
iteration    184: loss: 0.325666, loss_ce: 0.376065, loss_dice: 0.275268
iteration    185: loss: 0.317238, loss_ce: 0.363222, loss_dice: 0.271254
iteration    186: loss: 0.335750, loss_ce: 0.397341, loss_dice: 0.274160
iteration    187: loss: 0.327758, loss_ce: 0.382604, loss_dice: 0.272912
iteration    188: loss: 0.329045, loss_ce: 0.386738, loss_dice: 0.271353
iteration    189: loss: 0.327509, loss_ce: 0.384108, loss_dice: 0.270910
iteration    190: loss: 0.322491, loss_ce: 0.371915, loss_dice: 0.273067
iteration    191: loss: 0.335332, loss_ce: 0.395542, loss_dice: 0.275121
iteration    192: loss: 0.332818, loss_ce: 0.392565, loss_dice: 0.273071
iteration    193: loss: 0.327831, loss_ce: 0.380944, loss_dice: 0.274718
iteration    194: loss: 0.326509, loss_ce: 0.379875, loss_dice: 0.273143
iteration    195: loss: 0.328166, loss_ce: 0.383064, loss_dice: 0.273268
iteration    196: loss: 0.321914, loss_ce: 0.374254, loss_dice: 0.269575
iteration    197: loss: 0.332862, loss_ce: 0.393469, loss_dice: 0.272254
iteration    198: loss: 0.325862, loss_ce: 0.377124, loss_dice: 0.274601
iteration    199: loss: 0.322323, loss_ce: 0.371917, loss_dice: 0.272730
iteration    200: loss: 0.338303, loss_ce: 0.399663, loss_dice: 0.276943
iteration    201: loss: 0.330753, loss_ce: 0.384351, loss_dice: 0.277155
iteration    202: loss: 0.331429, loss_ce: 0.383271, loss_dice: 0.279588
iteration    203: loss: 0.313998, loss_ce: 0.356748, loss_dice: 0.271249
iteration    204: loss: 0.305234, loss_ce: 0.341910, loss_dice: 0.268558
iteration    205: loss: 0.322642, loss_ce: 0.372242, loss_dice: 0.273042
iteration    206: loss: 0.339403, loss_ce: 0.396561, loss_dice: 0.282245
iteration    207: loss: 0.318006, loss_ce: 0.366406, loss_dice: 0.269607
iteration    208: loss: 0.326428, loss_ce: 0.386014, loss_dice: 0.266843
iteration    209: loss: 0.330390, loss_ce: 0.388864, loss_dice: 0.271916
iteration    210: loss: 0.320607, loss_ce: 0.370271, loss_dice: 0.270943
iteration    211: loss: 0.325390, loss_ce: 0.380949, loss_dice: 0.269832
iteration    212: loss: 0.335560, loss_ce: 0.399587, loss_dice: 0.271532
iteration    213: loss: 0.326435, loss_ce: 0.379290, loss_dice: 0.273580
iteration    214: loss: 0.321249, loss_ce: 0.373237, loss_dice: 0.269261
iteration    215: loss: 0.317830, loss_ce: 0.368423, loss_dice: 0.267237
iteration    216: loss: 0.320783, loss_ce: 0.372203, loss_dice: 0.269364
iteration    217: loss: 0.334736, loss_ce: 0.398209, loss_dice: 0.271263
iteration    218: loss: 0.324467, loss_ce: 0.381445, loss_dice: 0.267488
iteration    219: loss: 0.328567, loss_ce: 0.386712, loss_dice: 0.270421
iteration    220: loss: 0.317868, loss_ce: 0.366104, loss_dice: 0.269632
iteration    221: loss: 0.329609, loss_ce: 0.386244, loss_dice: 0.272975
iteration    222: loss: 0.320763, loss_ce: 0.371065, loss_dice: 0.270460
iteration    223: loss: 0.319545, loss_ce: 0.369849, loss_dice: 0.269241
iteration    224: loss: 0.327057, loss_ce: 0.377490, loss_dice: 0.276624
iteration    225: loss: 0.319923, loss_ce: 0.368277, loss_dice: 0.271570
iteration    226: loss: 0.313163, loss_ce: 0.357827, loss_dice: 0.268499
iteration    227: loss: 0.325118, loss_ce: 0.379500, loss_dice: 0.270736
iteration    228: loss: 0.320354, loss_ce: 0.369513, loss_dice: 0.271195
iteration    229: loss: 0.321899, loss_ce: 0.375463, loss_dice: 0.268335
iteration    230: loss: 0.320113, loss_ce: 0.375114, loss_dice: 0.265113
iteration    231: loss: 0.320712, loss_ce: 0.372537, loss_dice: 0.268886
iteration    232: loss: 0.320106, loss_ce: 0.368410, loss_dice: 0.271801
iteration    233: loss: 0.318638, loss_ce: 0.365699, loss_dice: 0.271576
iteration    234: loss: 0.317255, loss_ce: 0.365278, loss_dice: 0.269232
iteration    235: loss: 0.308374, loss_ce: 0.347809, loss_dice: 0.268940
iteration    236: loss: 0.332640, loss_ce: 0.391295, loss_dice: 0.273986
iteration    237: loss: 0.325448, loss_ce: 0.379013, loss_dice: 0.271883
iteration    238: loss: 0.312290, loss_ce: 0.361054, loss_dice: 0.263526
iteration    239: loss: 0.329746, loss_ce: 0.387112, loss_dice: 0.272379
iteration    240: loss: 0.317385, loss_ce: 0.366808, loss_dice: 0.267962
iteration    241: loss: 0.330957, loss_ce: 0.389360, loss_dice: 0.272553
iteration    242: loss: 0.321910, loss_ce: 0.373302, loss_dice: 0.270518
iteration    243: loss: 0.315483, loss_ce: 0.362238, loss_dice: 0.268729
iteration    244: loss: 0.310226, loss_ce: 0.353481, loss_dice: 0.266972
iteration    245: loss: 0.309233, loss_ce: 0.353106, loss_dice: 0.265359
iteration    246: loss: 0.331416, loss_ce: 0.386483, loss_dice: 0.276349
iteration    247: loss: 0.315311, loss_ce: 0.363176, loss_dice: 0.267447
iteration    248: loss: 0.318796, loss_ce: 0.371716, loss_dice: 0.265877
iteration    249: loss: 0.330046, loss_ce: 0.382211, loss_dice: 0.277882
iteration    250: loss: 0.324505, loss_ce: 0.375209, loss_dice: 0.273801
iteration    251: loss: 0.316782, loss_ce: 0.367212, loss_dice: 0.266352
iteration    252: loss: 0.328072, loss_ce: 0.391511, loss_dice: 0.264633
iteration    253: loss: 0.322306, loss_ce: 0.376910, loss_dice: 0.267702
iteration    254: loss: 0.316186, loss_ce: 0.369086, loss_dice: 0.263286
iteration    255: loss: 0.308797, loss_ce: 0.355660, loss_dice: 0.261933
iteration    256: loss: 0.327491, loss_ce: 0.386319, loss_dice: 0.268663
iteration    257: loss: 0.308957, loss_ce: 0.354560, loss_dice: 0.263353
iteration    258: loss: 0.312116, loss_ce: 0.359725, loss_dice: 0.264507
iteration    259: loss: 0.330757, loss_ce: 0.392755, loss_dice: 0.268759
iteration    260: loss: 0.328384, loss_ce: 0.386550, loss_dice: 0.270218
iteration    261: loss: 0.319057, loss_ce: 0.365882, loss_dice: 0.272231
iteration    262: loss: 0.333542, loss_ce: 0.396491, loss_dice: 0.270593
iteration    263: loss: 0.320602, loss_ce: 0.371575, loss_dice: 0.269629
iteration    264: loss: 0.324236, loss_ce: 0.378654, loss_dice: 0.269819
iteration    265: loss: 0.322440, loss_ce: 0.377440, loss_dice: 0.267440
iteration    266: loss: 0.319982, loss_ce: 0.370509, loss_dice: 0.269455
iteration    267: loss: 0.326997, loss_ce: 0.386405, loss_dice: 0.267589
iteration    268: loss: 0.317330, loss_ce: 0.368382, loss_dice: 0.266278
iteration    269: loss: 0.325903, loss_ce: 0.382182, loss_dice: 0.269624
iteration    270: loss: 0.322372, loss_ce: 0.379976, loss_dice: 0.264769
iteration    271: loss: 0.318849, loss_ce: 0.370436, loss_dice: 0.267262
iteration    272: loss: 0.321163, loss_ce: 0.377030, loss_dice: 0.265297
iteration    273: loss: 0.318707, loss_ce: 0.369897, loss_dice: 0.267517
iteration    274: loss: 0.332793, loss_ce: 0.394492, loss_dice: 0.271094
iteration    275: loss: 0.321350, loss_ce: 0.373994, loss_dice: 0.268706
iteration    276: loss: 0.322117, loss_ce: 0.377946, loss_dice: 0.266287
iteration    277: loss: 0.310821, loss_ce: 0.354194, loss_dice: 0.267448
iteration    278: loss: 0.309163, loss_ce: 0.358614, loss_dice: 0.259712
iteration    279: loss: 0.314673, loss_ce: 0.364705, loss_dice: 0.264642
iteration    280: loss: 0.312501, loss_ce: 0.360644, loss_dice: 0.264358
iteration    281: loss: 0.333652, loss_ce: 0.393675, loss_dice: 0.273630
iteration    282: loss: 0.325347, loss_ce: 0.383012, loss_dice: 0.267681
iteration    283: loss: 0.319056, loss_ce: 0.373960, loss_dice: 0.264152
iteration    284: loss: 0.317841, loss_ce: 0.369648, loss_dice: 0.266033
iteration    285: loss: 0.307007, loss_ce: 0.360405, loss_dice: 0.253610
iteration    286: loss: 0.329488, loss_ce: 0.390959, loss_dice: 0.268017
iteration    287: loss: 0.315566, loss_ce: 0.364206, loss_dice: 0.266925
iteration    288: loss: 0.324724, loss_ce: 0.384812, loss_dice: 0.264636
iteration    289: loss: 0.324504, loss_ce: 0.381549, loss_dice: 0.267459
iteration    290: loss: 0.326476, loss_ce: 0.384036, loss_dice: 0.268917
iteration    291: loss: 0.328219, loss_ce: 0.386880, loss_dice: 0.269559
iteration    292: loss: 0.319518, loss_ce: 0.372177, loss_dice: 0.266859
iteration    293: loss: 0.312500, loss_ce: 0.364083, loss_dice: 0.260918
iteration    294: loss: 0.323206, loss_ce: 0.383831, loss_dice: 0.262581
iteration    295: loss: 0.320653, loss_ce: 0.376755, loss_dice: 0.264552
iteration    296: loss: 0.313983, loss_ce: 0.363403, loss_dice: 0.264562
iteration    297: loss: 0.306817, loss_ce: 0.356088, loss_dice: 0.257545
iteration    298: loss: 0.305317, loss_ce: 0.350198, loss_dice: 0.260436
iteration    299: loss: 0.306512, loss_ce: 0.357844, loss_dice: 0.255180
iteration    300: loss: 0.306567, loss_ce: 0.354542, loss_dice: 0.258593
iteration    301: loss: 0.315972, loss_ce: 0.369430, loss_dice: 0.262514
iteration    302: loss: 0.329960, loss_ce: 0.390813, loss_dice: 0.269108
iteration    303: loss: 0.323303, loss_ce: 0.378729, loss_dice: 0.267877
iteration    304: loss: 0.309679, loss_ce: 0.361307, loss_dice: 0.258050
iteration    305: loss: 0.311490, loss_ce: 0.356685, loss_dice: 0.266296
iteration    306: loss: 0.315582, loss_ce: 0.367764, loss_dice: 0.263400
iteration    307: loss: 0.322060, loss_ce: 0.376917, loss_dice: 0.267204
iteration    308: loss: 0.315596, loss_ce: 0.368133, loss_dice: 0.263058
iteration    309: loss: 0.298831, loss_ce: 0.336451, loss_dice: 0.261211
iteration    310: loss: 0.320761, loss_ce: 0.376595, loss_dice: 0.264927
iteration    311: loss: 0.321608, loss_ce: 0.378311, loss_dice: 0.264904
iteration    312: loss: 0.316809, loss_ce: 0.368705, loss_dice: 0.264912
iteration    313: loss: 0.317679, loss_ce: 0.370386, loss_dice: 0.264971
iteration    314: loss: 0.307605, loss_ce: 0.355806, loss_dice: 0.259405
iteration    315: loss: 0.320529, loss_ce: 0.380021, loss_dice: 0.261036
iteration    316: loss: 0.305038, loss_ce: 0.352720, loss_dice: 0.257355
iteration    317: loss: 0.310826, loss_ce: 0.362549, loss_dice: 0.259103
iteration    318: loss: 0.318392, loss_ce: 0.371830, loss_dice: 0.264953
iteration    319: loss: 0.309377, loss_ce: 0.359844, loss_dice: 0.258909
iteration    320: loss: 0.318530, loss_ce: 0.370854, loss_dice: 0.266207
iteration    321: loss: 0.321291, loss_ce: 0.381393, loss_dice: 0.261189
iteration    322: loss: 0.335201, loss_ce: 0.402484, loss_dice: 0.267918
iteration    323: loss: 0.318542, loss_ce: 0.373252, loss_dice: 0.263832
iteration    324: loss: 0.319354, loss_ce: 0.372685, loss_dice: 0.266023
iteration    325: loss: 0.317850, loss_ce: 0.373467, loss_dice: 0.262234
iteration    326: loss: 0.316672, loss_ce: 0.371859, loss_dice: 0.261485
iteration    327: loss: 0.315576, loss_ce: 0.373279, loss_dice: 0.257873
iteration    328: loss: 0.316659, loss_ce: 0.370992, loss_dice: 0.262326
iteration    329: loss: 0.306634, loss_ce: 0.358643, loss_dice: 0.254625
iteration    330: loss: 0.310362, loss_ce: 0.359517, loss_dice: 0.261207
iteration    331: loss: 0.328115, loss_ce: 0.390926, loss_dice: 0.265304
iteration    332: loss: 0.309821, loss_ce: 0.363547, loss_dice: 0.256095
iteration    333: loss: 0.332153, loss_ce: 0.397804, loss_dice: 0.266503
iteration    334: loss: 0.316095, loss_ce: 0.371025, loss_dice: 0.261166
iteration    335: loss: 0.316058, loss_ce: 0.367320, loss_dice: 0.264796
iteration    336: loss: 0.315178, loss_ce: 0.363800, loss_dice: 0.266555
iteration    337: loss: 0.320676, loss_ce: 0.374857, loss_dice: 0.266496
iteration    338: loss: 0.310249, loss_ce: 0.359043, loss_dice: 0.261454
save model to ../model/TVD_Degradation[64, 64, 64]/TVD_ViT-B_16_vitpatch[8, 8, 8]_epo4_bs48_lr0.01_seed1234/epoch_1.pth
 50%|██████████████▌              | 2/4 [2:22:57<2:22:58, 4289.08s/it]iteration    339: loss: 0.312109, loss_ce: 0.358330, loss_dice: 0.265888
iteration    340: loss: 0.316493, loss_ce: 0.374906, loss_dice: 0.258080
iteration    341: loss: 0.312219, loss_ce: 0.367057, loss_dice: 0.257382
iteration    342: loss: 0.316004, loss_ce: 0.368249, loss_dice: 0.263760
iteration    343: loss: 0.325215, loss_ce: 0.386262, loss_dice: 0.264168
iteration    344: loss: 0.327322, loss_ce: 0.387386, loss_dice: 0.267258
iteration    345: loss: 0.318231, loss_ce: 0.372363, loss_dice: 0.264098
iteration    346: loss: 0.305931, loss_ce: 0.356011, loss_dice: 0.255852
iteration    347: loss: 0.315331, loss_ce: 0.369334, loss_dice: 0.261329
iteration    348: loss: 0.318182, loss_ce: 0.376493, loss_dice: 0.259870
iteration    349: loss: 0.311946, loss_ce: 0.365456, loss_dice: 0.258435
iteration    350: loss: 0.313497, loss_ce: 0.364839, loss_dice: 0.262155
iteration    351: loss: 0.316792, loss_ce: 0.368469, loss_dice: 0.265116
iteration    352: loss: 0.310590, loss_ce: 0.361920, loss_dice: 0.259261
iteration    353: loss: 0.321848, loss_ce: 0.375669, loss_dice: 0.268027
iteration    354: loss: 0.314403, loss_ce: 0.364758, loss_dice: 0.264048
iteration    355: loss: 0.309153, loss_ce: 0.354789, loss_dice: 0.263516
iteration    356: loss: 0.313828, loss_ce: 0.366924, loss_dice: 0.260731
iteration    357: loss: 0.318034, loss_ce: 0.370764, loss_dice: 0.265303
iteration    358: loss: 0.308728, loss_ce: 0.355349, loss_dice: 0.262106
iteration    359: loss: 0.329150, loss_ce: 0.391747, loss_dice: 0.266553
iteration    360: loss: 0.311889, loss_ce: 0.366097, loss_dice: 0.257680
iteration    361: loss: 0.315978, loss_ce: 0.365395, loss_dice: 0.266562
iteration    362: loss: 0.320511, loss_ce: 0.378227, loss_dice: 0.262796
iteration    363: loss: 0.323023, loss_ce: 0.379739, loss_dice: 0.266308
iteration    364: loss: 0.314742, loss_ce: 0.370671, loss_dice: 0.258812
iteration    365: loss: 0.315047, loss_ce: 0.369085, loss_dice: 0.261008
iteration    366: loss: 0.308505, loss_ce: 0.357494, loss_dice: 0.259516
iteration    367: loss: 0.319861, loss_ce: 0.379724, loss_dice: 0.259999
iteration    368: loss: 0.304906, loss_ce: 0.354559, loss_dice: 0.255253
iteration    369: loss: 0.320050, loss_ce: 0.375812, loss_dice: 0.264288
iteration    370: loss: 0.302359, loss_ce: 0.351899, loss_dice: 0.252818
iteration    371: loss: 0.313843, loss_ce: 0.360821, loss_dice: 0.266866
iteration    372: loss: 0.298816, loss_ce: 0.337560, loss_dice: 0.260072
iteration    373: loss: 0.302226, loss_ce: 0.347897, loss_dice: 0.256555
iteration    374: loss: 0.293324, loss_ce: 0.332887, loss_dice: 0.253762
iteration    375: loss: 0.336097, loss_ce: 0.399817, loss_dice: 0.272377
iteration    376: loss: 0.320769, loss_ce: 0.373987, loss_dice: 0.267551
iteration    377: loss: 0.318360, loss_ce: 0.376197, loss_dice: 0.260523
iteration    378: loss: 0.311491, loss_ce: 0.366867, loss_dice: 0.256114
iteration    379: loss: 0.312561, loss_ce: 0.362880, loss_dice: 0.262243
iteration    380: loss: 0.317187, loss_ce: 0.368577, loss_dice: 0.265796
iteration    381: loss: 0.322545, loss_ce: 0.377698, loss_dice: 0.267392
iteration    382: loss: 0.312865, loss_ce: 0.363548, loss_dice: 0.262182
iteration    383: loss: 0.311405, loss_ce: 0.361850, loss_dice: 0.260960
iteration    384: loss: 0.312937, loss_ce: 0.367120, loss_dice: 0.258754
iteration    385: loss: 0.311471, loss_ce: 0.363433, loss_dice: 0.259510
iteration    386: loss: 0.310323, loss_ce: 0.362964, loss_dice: 0.257682
iteration    387: loss: 0.306309, loss_ce: 0.356431, loss_dice: 0.256186
iteration    388: loss: 0.316177, loss_ce: 0.368799, loss_dice: 0.263555
iteration    389: loss: 0.313243, loss_ce: 0.366327, loss_dice: 0.260159
iteration    390: loss: 0.313792, loss_ce: 0.368513, loss_dice: 0.259072
iteration    391: loss: 0.316414, loss_ce: 0.369736, loss_dice: 0.263092
iteration    392: loss: 0.310944, loss_ce: 0.361980, loss_dice: 0.259908
iteration    393: loss: 0.322452, loss_ce: 0.380515, loss_dice: 0.264390
iteration    394: loss: 0.311693, loss_ce: 0.365082, loss_dice: 0.258304
iteration    395: loss: 0.312553, loss_ce: 0.365895, loss_dice: 0.259211
iteration    396: loss: 0.317495, loss_ce: 0.377581, loss_dice: 0.257410
iteration    397: loss: 0.322608, loss_ce: 0.384615, loss_dice: 0.260602
iteration    398: loss: 0.310589, loss_ce: 0.362646, loss_dice: 0.258532
iteration    399: loss: 0.302671, loss_ce: 0.351862, loss_dice: 0.253480
iteration    400: loss: 0.314228, loss_ce: 0.369588, loss_dice: 0.258867
iteration    401: loss: 0.302579, loss_ce: 0.350490, loss_dice: 0.254668
iteration    402: loss: 0.309310, loss_ce: 0.360505, loss_dice: 0.258115
iteration    403: loss: 0.319780, loss_ce: 0.377774, loss_dice: 0.261787
iteration    404: loss: 0.311098, loss_ce: 0.363903, loss_dice: 0.258293
iteration    405: loss: 0.314540, loss_ce: 0.370707, loss_dice: 0.258373
iteration    406: loss: 0.308152, loss_ce: 0.361915, loss_dice: 0.254388
iteration    407: loss: 0.303244, loss_ce: 0.353820, loss_dice: 0.252668
iteration    408: loss: 0.321089, loss_ce: 0.375279, loss_dice: 0.266900
iteration    409: loss: 0.313164, loss_ce: 0.367360, loss_dice: 0.258967
iteration    410: loss: 0.339799, loss_ce: 0.409394, loss_dice: 0.270205
iteration    411: loss: 0.302759, loss_ce: 0.348339, loss_dice: 0.257178
iteration    412: loss: 0.302067, loss_ce: 0.354078, loss_dice: 0.250056
iteration    413: loss: 0.320091, loss_ce: 0.376588, loss_dice: 0.263594
iteration    414: loss: 0.317095, loss_ce: 0.367670, loss_dice: 0.266521
iteration    415: loss: 0.311005, loss_ce: 0.361255, loss_dice: 0.260754
iteration    416: loss: 0.321857, loss_ce: 0.383580, loss_dice: 0.260134
iteration    417: loss: 0.305423, loss_ce: 0.357215, loss_dice: 0.253632
iteration    418: loss: 0.306649, loss_ce: 0.360180, loss_dice: 0.253117
iteration    419: loss: 0.304727, loss_ce: 0.346615, loss_dice: 0.262838
iteration    420: loss: 0.300712, loss_ce: 0.349902, loss_dice: 0.251522
iteration    421: loss: 0.307618, loss_ce: 0.362451, loss_dice: 0.252786
iteration    422: loss: 0.314130, loss_ce: 0.371411, loss_dice: 0.256849
iteration    423: loss: 0.308502, loss_ce: 0.359061, loss_dice: 0.257943
iteration    424: loss: 0.308513, loss_ce: 0.356371, loss_dice: 0.260655
iteration    425: loss: 0.316384, loss_ce: 0.372221, loss_dice: 0.260547
iteration    426: loss: 0.314799, loss_ce: 0.364534, loss_dice: 0.265065
iteration    427: loss: 0.308922, loss_ce: 0.355782, loss_dice: 0.262062
iteration    428: loss: 0.311439, loss_ce: 0.368814, loss_dice: 0.254065
iteration    429: loss: 0.308796, loss_ce: 0.356931, loss_dice: 0.260662
iteration    430: loss: 0.319183, loss_ce: 0.377595, loss_dice: 0.260770
iteration    431: loss: 0.302790, loss_ce: 0.352158, loss_dice: 0.253423
iteration    432: loss: 0.313710, loss_ce: 0.366073, loss_dice: 0.261347
iteration    433: loss: 0.305615, loss_ce: 0.356665, loss_dice: 0.254564
iteration    434: loss: 0.309541, loss_ce: 0.359211, loss_dice: 0.259871
iteration    435: loss: 0.323613, loss_ce: 0.384706, loss_dice: 0.262521
iteration    436: loss: 0.310622, loss_ce: 0.363247, loss_dice: 0.257997
iteration    437: loss: 0.319367, loss_ce: 0.377107, loss_dice: 0.261627
iteration    438: loss: 0.317317, loss_ce: 0.377338, loss_dice: 0.257297
iteration    439: loss: 0.315495, loss_ce: 0.371913, loss_dice: 0.259077
iteration    440: loss: 0.311412, loss_ce: 0.367755, loss_dice: 0.255070
iteration    441: loss: 0.312660, loss_ce: 0.366430, loss_dice: 0.258890
iteration    442: loss: 0.321627, loss_ce: 0.382222, loss_dice: 0.261033
iteration    443: loss: 0.305770, loss_ce: 0.354571, loss_dice: 0.256969
iteration    444: loss: 0.312738, loss_ce: 0.368140, loss_dice: 0.257336
iteration    445: loss: 0.297135, loss_ce: 0.334138, loss_dice: 0.260132
iteration    446: loss: 0.313328, loss_ce: 0.361153, loss_dice: 0.265504
iteration    447: loss: 0.318036, loss_ce: 0.374151, loss_dice: 0.261921
iteration    448: loss: 0.309101, loss_ce: 0.364080, loss_dice: 0.254123
iteration    449: loss: 0.305830, loss_ce: 0.356550, loss_dice: 0.255111
iteration    450: loss: 0.312822, loss_ce: 0.366324, loss_dice: 0.259321
iteration    451: loss: 0.307992, loss_ce: 0.359112, loss_dice: 0.256871
iteration    452: loss: 0.308016, loss_ce: 0.356180, loss_dice: 0.259853
iteration    453: loss: 0.302373, loss_ce: 0.354441, loss_dice: 0.250305
iteration    454: loss: 0.313026, loss_ce: 0.367860, loss_dice: 0.258193
iteration    455: loss: 0.303186, loss_ce: 0.351042, loss_dice: 0.255330
iteration    456: loss: 0.312286, loss_ce: 0.363897, loss_dice: 0.260674
iteration    457: loss: 0.320943, loss_ce: 0.377765, loss_dice: 0.264120
iteration    458: loss: 0.326717, loss_ce: 0.386548, loss_dice: 0.266887
iteration    459: loss: 0.313262, loss_ce: 0.368874, loss_dice: 0.257650
iteration    460: loss: 0.309422, loss_ce: 0.361851, loss_dice: 0.256993
iteration    461: loss: 0.300780, loss_ce: 0.343908, loss_dice: 0.257653
iteration    462: loss: 0.302220, loss_ce: 0.349168, loss_dice: 0.255273
iteration    463: loss: 0.313502, loss_ce: 0.367221, loss_dice: 0.259784
iteration    464: loss: 0.304084, loss_ce: 0.351754, loss_dice: 0.256415
iteration    465: loss: 0.302621, loss_ce: 0.354848, loss_dice: 0.250394
iteration    466: loss: 0.314308, loss_ce: 0.364945, loss_dice: 0.263672
iteration    467: loss: 0.309365, loss_ce: 0.364267, loss_dice: 0.254462
iteration    468: loss: 0.313273, loss_ce: 0.368933, loss_dice: 0.257613
iteration    469: loss: 0.311485, loss_ce: 0.366646, loss_dice: 0.256325
iteration    470: loss: 0.310846, loss_ce: 0.368716, loss_dice: 0.252976
iteration    471: loss: 0.310518, loss_ce: 0.362210, loss_dice: 0.258826
iteration    472: loss: 0.316062, loss_ce: 0.375482, loss_dice: 0.256641
iteration    473: loss: 0.305063, loss_ce: 0.352525, loss_dice: 0.257600
iteration    474: loss: 0.310611, loss_ce: 0.368064, loss_dice: 0.253158
iteration    475: loss: 0.310306, loss_ce: 0.362211, loss_dice: 0.258401
iteration    476: loss: 0.317631, loss_ce: 0.372528, loss_dice: 0.262734
iteration    477: loss: 0.308078, loss_ce: 0.360036, loss_dice: 0.256119
iteration    478: loss: 0.309558, loss_ce: 0.362754, loss_dice: 0.256363
iteration    479: loss: 0.309043, loss_ce: 0.361904, loss_dice: 0.256182
iteration    480: loss: 0.296293, loss_ce: 0.340556, loss_dice: 0.252030
iteration    481: loss: 0.292632, loss_ce: 0.337076, loss_dice: 0.248188
iteration    482: loss: 0.303278, loss_ce: 0.353374, loss_dice: 0.253181
iteration    483: loss: 0.314506, loss_ce: 0.369734, loss_dice: 0.259278
iteration    484: loss: 0.316469, loss_ce: 0.373906, loss_dice: 0.259032
iteration    485: loss: 0.326558, loss_ce: 0.388577, loss_dice: 0.264538
iteration    486: loss: 0.319588, loss_ce: 0.377826, loss_dice: 0.261349
iteration    487: loss: 0.307739, loss_ce: 0.359162, loss_dice: 0.256315
iteration    488: loss: 0.315398, loss_ce: 0.374506, loss_dice: 0.256291
iteration    489: loss: 0.322541, loss_ce: 0.382230, loss_dice: 0.262851
iteration    490: loss: 0.319131, loss_ce: 0.378630, loss_dice: 0.259633
iteration    491: loss: 0.314580, loss_ce: 0.371412, loss_dice: 0.257748
iteration    492: loss: 0.317573, loss_ce: 0.374817, loss_dice: 0.260329
iteration    493: loss: 0.303840, loss_ce: 0.352982, loss_dice: 0.254697
iteration    494: loss: 0.308782, loss_ce: 0.359639, loss_dice: 0.257924
iteration    495: loss: 0.318623, loss_ce: 0.377694, loss_dice: 0.259552
iteration    496: loss: 0.307628, loss_ce: 0.360671, loss_dice: 0.254585
iteration    497: loss: 0.318162, loss_ce: 0.379124, loss_dice: 0.257200
iteration    498: loss: 0.304698, loss_ce: 0.360969, loss_dice: 0.248427
iteration    499: loss: 0.309664, loss_ce: 0.363569, loss_dice: 0.255759
iteration    500: loss: 0.304513, loss_ce: 0.355506, loss_dice: 0.253520
iteration    501: loss: 0.313309, loss_ce: 0.361189, loss_dice: 0.265430
iteration    502: loss: 0.311850, loss_ce: 0.364675, loss_dice: 0.259025
iteration    503: loss: 0.293708, loss_ce: 0.337983, loss_dice: 0.249433
iteration    504: loss: 0.297395, loss_ce: 0.341922, loss_dice: 0.252868
iteration    505: loss: 0.305928, loss_ce: 0.354988, loss_dice: 0.256867
iteration    506: loss: 0.319655, loss_ce: 0.382951, loss_dice: 0.256358
iteration    507: loss: 0.312387, loss_ce: 0.368933, loss_dice: 0.255841
save model to ../model/TVD_Degradation[64, 64, 64]/TVD_ViT-B_16_vitpatch[8, 8, 8]_epo4_bs48_lr0.01_seed1234/epoch_2.pth
 75%|█████████████████████▊       | 3/4 [3:34:54<1:11:41, 4301.76s/it]iteration    508: loss: 0.302601, loss_ce: 0.355098, loss_dice: 0.250104
iteration    509: loss: 0.312915, loss_ce: 0.369281, loss_dice: 0.256550
iteration    510: loss: 0.316596, loss_ce: 0.372067, loss_dice: 0.261125
iteration    511: loss: 0.310164, loss_ce: 0.365238, loss_dice: 0.255090
iteration    512: loss: 0.312727, loss_ce: 0.371462, loss_dice: 0.253992
iteration    513: loss: 0.305765, loss_ce: 0.360280, loss_dice: 0.251250
iteration    514: loss: 0.314798, loss_ce: 0.373141, loss_dice: 0.256455
iteration    515: loss: 0.307332, loss_ce: 0.354451, loss_dice: 0.260214
iteration    516: loss: 0.312925, loss_ce: 0.367207, loss_dice: 0.258642
iteration    517: loss: 0.319483, loss_ce: 0.382888, loss_dice: 0.256077
iteration    518: loss: 0.312309, loss_ce: 0.369957, loss_dice: 0.254662
iteration    519: loss: 0.322054, loss_ce: 0.385709, loss_dice: 0.258399
iteration    520: loss: 0.303837, loss_ce: 0.353720, loss_dice: 0.253953
iteration    521: loss: 0.317281, loss_ce: 0.373498, loss_dice: 0.261063
iteration    522: loss: 0.307042, loss_ce: 0.362233, loss_dice: 0.251851
iteration    523: loss: 0.304063, loss_ce: 0.354732, loss_dice: 0.253394
iteration    524: loss: 0.313180, loss_ce: 0.374090, loss_dice: 0.252270
iteration    525: loss: 0.319018, loss_ce: 0.382708, loss_dice: 0.255327
iteration    526: loss: 0.308762, loss_ce: 0.358450, loss_dice: 0.259074
iteration    527: loss: 0.306092, loss_ce: 0.358069, loss_dice: 0.254115
iteration    528: loss: 0.309922, loss_ce: 0.358561, loss_dice: 0.261284
iteration    529: loss: 0.309425, loss_ce: 0.359852, loss_dice: 0.258998
iteration    530: loss: 0.298498, loss_ce: 0.343920, loss_dice: 0.253077
iteration    531: loss: 0.294623, loss_ce: 0.335687, loss_dice: 0.253559
iteration    532: loss: 0.310332, loss_ce: 0.368313, loss_dice: 0.252351
iteration    533: loss: 0.309291, loss_ce: 0.366830, loss_dice: 0.251752
iteration    534: loss: 0.309289, loss_ce: 0.365330, loss_dice: 0.253247
iteration    535: loss: 0.304192, loss_ce: 0.355394, loss_dice: 0.252991
iteration    536: loss: 0.314191, loss_ce: 0.368982, loss_dice: 0.259400
iteration    537: loss: 0.305373, loss_ce: 0.361226, loss_dice: 0.249519
iteration    538: loss: 0.315974, loss_ce: 0.371571, loss_dice: 0.260377
iteration    539: loss: 0.304420, loss_ce: 0.352330, loss_dice: 0.256509
iteration    540: loss: 0.318657, loss_ce: 0.382146, loss_dice: 0.255169
iteration    541: loss: 0.305027, loss_ce: 0.354967, loss_dice: 0.255088
iteration    542: loss: 0.303111, loss_ce: 0.352617, loss_dice: 0.253605
iteration    543: loss: 0.311579, loss_ce: 0.366409, loss_dice: 0.256750
iteration    544: loss: 0.312028, loss_ce: 0.365086, loss_dice: 0.258969
iteration    545: loss: 0.308770, loss_ce: 0.366256, loss_dice: 0.251285
iteration    546: loss: 0.295330, loss_ce: 0.343530, loss_dice: 0.247130
iteration    547: loss: 0.311372, loss_ce: 0.361950, loss_dice: 0.260793
iteration    548: loss: 0.309469, loss_ce: 0.364601, loss_dice: 0.254337
iteration    549: loss: 0.320875, loss_ce: 0.384158, loss_dice: 0.257591
iteration    550: loss: 0.298614, loss_ce: 0.346177, loss_dice: 0.251051
iteration    551: loss: 0.311953, loss_ce: 0.369900, loss_dice: 0.254005
iteration    552: loss: 0.330215, loss_ce: 0.398735, loss_dice: 0.261695
iteration    553: loss: 0.311011, loss_ce: 0.362992, loss_dice: 0.259030
iteration    554: loss: 0.311442, loss_ce: 0.364048, loss_dice: 0.258836
iteration    555: loss: 0.309284, loss_ce: 0.364938, loss_dice: 0.253631
iteration    556: loss: 0.311504, loss_ce: 0.371451, loss_dice: 0.251558
iteration    557: loss: 0.305873, loss_ce: 0.357587, loss_dice: 0.254160
iteration    558: loss: 0.307303, loss_ce: 0.357200, loss_dice: 0.257406
iteration    559: loss: 0.313192, loss_ce: 0.362118, loss_dice: 0.264266
iteration    560: loss: 0.308878, loss_ce: 0.361014, loss_dice: 0.256742
iteration    561: loss: 0.305827, loss_ce: 0.355695, loss_dice: 0.255960
iteration    562: loss: 0.305420, loss_ce: 0.352676, loss_dice: 0.258164
iteration    563: loss: 0.298356, loss_ce: 0.346538, loss_dice: 0.250174
iteration    564: loss: 0.302521, loss_ce: 0.351570, loss_dice: 0.253472
iteration    565: loss: 0.315917, loss_ce: 0.375768, loss_dice: 0.256067
iteration    566: loss: 0.319677, loss_ce: 0.379196, loss_dice: 0.260159
iteration    567: loss: 0.308976, loss_ce: 0.362627, loss_dice: 0.255324
iteration    568: loss: 0.319467, loss_ce: 0.378947, loss_dice: 0.259987
iteration    569: loss: 0.305632, loss_ce: 0.360634, loss_dice: 0.250630
iteration    570: loss: 0.312721, loss_ce: 0.371625, loss_dice: 0.253818
iteration    571: loss: 0.314842, loss_ce: 0.370528, loss_dice: 0.259156
iteration    572: loss: 0.313112, loss_ce: 0.370658, loss_dice: 0.255566
iteration    573: loss: 0.301394, loss_ce: 0.350510, loss_dice: 0.252279
iteration    574: loss: 0.295849, loss_ce: 0.341913, loss_dice: 0.249784
iteration    575: loss: 0.299297, loss_ce: 0.346303, loss_dice: 0.252292
iteration    576: loss: 0.308914, loss_ce: 0.361864, loss_dice: 0.255964
iteration    577: loss: 0.310666, loss_ce: 0.359984, loss_dice: 0.261347
iteration    578: loss: 0.302960, loss_ce: 0.351789, loss_dice: 0.254132
iteration    579: loss: 0.302353, loss_ce: 0.350883, loss_dice: 0.253823
iteration    580: loss: 0.308090, loss_ce: 0.360823, loss_dice: 0.255358
iteration    581: loss: 0.304611, loss_ce: 0.355221, loss_dice: 0.254001
iteration    582: loss: 0.311968, loss_ce: 0.370214, loss_dice: 0.253723
iteration    583: loss: 0.302841, loss_ce: 0.356706, loss_dice: 0.248975
iteration    584: loss: 0.304635, loss_ce: 0.351428, loss_dice: 0.257843
iteration    585: loss: 0.308006, loss_ce: 0.357586, loss_dice: 0.258427
iteration    586: loss: 0.303352, loss_ce: 0.352751, loss_dice: 0.253954
iteration    587: loss: 0.312160, loss_ce: 0.365582, loss_dice: 0.258738
iteration    588: loss: 0.308351, loss_ce: 0.363443, loss_dice: 0.253259
iteration    589: loss: 0.292570, loss_ce: 0.338593, loss_dice: 0.246548
iteration    590: loss: 0.306490, loss_ce: 0.357177, loss_dice: 0.255804
iteration    591: loss: 0.306746, loss_ce: 0.361673, loss_dice: 0.251819
iteration    592: loss: 0.300545, loss_ce: 0.352074, loss_dice: 0.249016
iteration    593: loss: 0.303271, loss_ce: 0.349509, loss_dice: 0.257032
iteration    594: loss: 0.300788, loss_ce: 0.352330, loss_dice: 0.249246
iteration    595: loss: 0.305863, loss_ce: 0.356142, loss_dice: 0.255585
iteration    596: loss: 0.311662, loss_ce: 0.370568, loss_dice: 0.252757
iteration    597: loss: 0.298962, loss_ce: 0.347676, loss_dice: 0.250247
iteration    598: loss: 0.309975, loss_ce: 0.361396, loss_dice: 0.258554
iteration    599: loss: 0.314367, loss_ce: 0.373299, loss_dice: 0.255436
iteration    600: loss: 0.295938, loss_ce: 0.341410, loss_dice: 0.250467
iteration    601: loss: 0.311994, loss_ce: 0.368640, loss_dice: 0.255347
iteration    602: loss: 0.306636, loss_ce: 0.361221, loss_dice: 0.252051
iteration    603: loss: 0.301207, loss_ce: 0.351682, loss_dice: 0.250732
iteration    604: loss: 0.307698, loss_ce: 0.358778, loss_dice: 0.256618
iteration    605: loss: 0.310453, loss_ce: 0.366836, loss_dice: 0.254070
iteration    606: loss: 0.306261, loss_ce: 0.360944, loss_dice: 0.251578
iteration    607: loss: 0.311631, loss_ce: 0.368387, loss_dice: 0.254875
iteration    608: loss: 0.314397, loss_ce: 0.370607, loss_dice: 0.258186
iteration    609: loss: 0.296809, loss_ce: 0.338968, loss_dice: 0.254650
iteration    610: loss: 0.311124, loss_ce: 0.364775, loss_dice: 0.257472
iteration    611: loss: 0.303355, loss_ce: 0.355410, loss_dice: 0.251299
iteration    612: loss: 0.307561, loss_ce: 0.360088, loss_dice: 0.255033
iteration    613: loss: 0.301212, loss_ce: 0.347922, loss_dice: 0.254503
iteration    614: loss: 0.309154, loss_ce: 0.368077, loss_dice: 0.250231
iteration    615: loss: 0.314465, loss_ce: 0.373626, loss_dice: 0.255303
iteration    616: loss: 0.283994, loss_ce: 0.320331, loss_dice: 0.247658
iteration    617: loss: 0.302759, loss_ce: 0.356568, loss_dice: 0.248951
iteration    618: loss: 0.313646, loss_ce: 0.369129, loss_dice: 0.258163
iteration    619: loss: 0.310498, loss_ce: 0.367382, loss_dice: 0.253613
iteration    620: loss: 0.314060, loss_ce: 0.368306, loss_dice: 0.259813
iteration    621: loss: 0.297530, loss_ce: 0.344351, loss_dice: 0.250708
iteration    622: loss: 0.305898, loss_ce: 0.355664, loss_dice: 0.256131
iteration    623: loss: 0.313009, loss_ce: 0.366625, loss_dice: 0.259393
iteration    624: loss: 0.320190, loss_ce: 0.381534, loss_dice: 0.258845
iteration    625: loss: 0.306442, loss_ce: 0.358783, loss_dice: 0.254101
iteration    626: loss: 0.310824, loss_ce: 0.367622, loss_dice: 0.254027
iteration    627: loss: 0.300957, loss_ce: 0.347651, loss_dice: 0.254263
iteration    628: loss: 0.325958, loss_ce: 0.388224, loss_dice: 0.263692
iteration    629: loss: 0.302668, loss_ce: 0.351289, loss_dice: 0.254046
iteration    630: loss: 0.321490, loss_ce: 0.383559, loss_dice: 0.259420
iteration    631: loss: 0.303103, loss_ce: 0.353384, loss_dice: 0.252822
iteration    632: loss: 0.303077, loss_ce: 0.352100, loss_dice: 0.254055
iteration    633: loss: 0.316486, loss_ce: 0.378903, loss_dice: 0.254069
iteration    634: loss: 0.306173, loss_ce: 0.353285, loss_dice: 0.259060
iteration    635: loss: 0.303126, loss_ce: 0.350282, loss_dice: 0.255970
iteration    636: loss: 0.313780, loss_ce: 0.368595, loss_dice: 0.258965
iteration    637: loss: 0.322172, loss_ce: 0.380926, loss_dice: 0.263417
iteration    638: loss: 0.296937, loss_ce: 0.342091, loss_dice: 0.251782
iteration    639: loss: 0.311095, loss_ce: 0.364434, loss_dice: 0.257755
iteration    640: loss: 0.303301, loss_ce: 0.354196, loss_dice: 0.252406
iteration    641: loss: 0.307087, loss_ce: 0.359831, loss_dice: 0.254342
iteration    642: loss: 0.304587, loss_ce: 0.360440, loss_dice: 0.248735
iteration    643: loss: 0.308859, loss_ce: 0.362141, loss_dice: 0.255578
iteration    644: loss: 0.299717, loss_ce: 0.344768, loss_dice: 0.254667
iteration    645: loss: 0.299104, loss_ce: 0.347187, loss_dice: 0.251021
iteration    646: loss: 0.301763, loss_ce: 0.353449, loss_dice: 0.250077
iteration    647: loss: 0.311434, loss_ce: 0.364626, loss_dice: 0.258243
iteration    648: loss: 0.303876, loss_ce: 0.356666, loss_dice: 0.251087
iteration    649: loss: 0.301835, loss_ce: 0.348742, loss_dice: 0.254928
iteration    650: loss: 0.315670, loss_ce: 0.373177, loss_dice: 0.258162
iteration    651: loss: 0.307814, loss_ce: 0.357132, loss_dice: 0.258495
iteration    652: loss: 0.292503, loss_ce: 0.333622, loss_dice: 0.251385
iteration    653: loss: 0.304922, loss_ce: 0.354511, loss_dice: 0.255333
iteration    654: loss: 0.290566, loss_ce: 0.333110, loss_dice: 0.248022
iteration    655: loss: 0.311916, loss_ce: 0.369985, loss_dice: 0.253848
iteration    656: loss: 0.311471, loss_ce: 0.366586, loss_dice: 0.256355
iteration    657: loss: 0.315300, loss_ce: 0.373923, loss_dice: 0.256676
iteration    658: loss: 0.323915, loss_ce: 0.383445, loss_dice: 0.264384
iteration    659: loss: 0.304374, loss_ce: 0.351658, loss_dice: 0.257090
iteration    660: loss: 0.297902, loss_ce: 0.346395, loss_dice: 0.249410
iteration    661: loss: 0.313496, loss_ce: 0.370831, loss_dice: 0.256161
iteration    662: loss: 0.306766, loss_ce: 0.361632, loss_dice: 0.251899
iteration    663: loss: 0.297707, loss_ce: 0.348399, loss_dice: 0.247015
iteration    664: loss: 0.302212, loss_ce: 0.355613, loss_dice: 0.248810
iteration    665: loss: 0.304931, loss_ce: 0.356753, loss_dice: 0.253110
iteration    666: loss: 0.318390, loss_ce: 0.382002, loss_dice: 0.254779
iteration    667: loss: 0.309798, loss_ce: 0.366402, loss_dice: 0.253195
iteration    668: loss: 0.306068, loss_ce: 0.358445, loss_dice: 0.253690
iteration    669: loss: 0.298768, loss_ce: 0.346704, loss_dice: 0.250833
iteration    670: loss: 0.316515, loss_ce: 0.375159, loss_dice: 0.257871
iteration    671: loss: 0.321531, loss_ce: 0.386097, loss_dice: 0.256966
iteration    672: loss: 0.311465, loss_ce: 0.364514, loss_dice: 0.258416
iteration    673: loss: 0.307765, loss_ce: 0.358275, loss_dice: 0.257254
iteration    674: loss: 0.314503, loss_ce: 0.374438, loss_dice: 0.254568
iteration    675: loss: 0.308096, loss_ce: 0.361707, loss_dice: 0.254486
iteration    676: loss: 0.306665, loss_ce: 0.357255, loss_dice: 0.256075
save model to ../model/TVD_Degradation[64, 64, 64]/TVD_ViT-B_16_vitpatch[8, 8, 8]_epo4_bs48_lr0.01_seed1234/epoch_3.pth
save model to ../model/TVD_Degradation[64, 64, 64]/TVD_ViT-B_16_vitpatch[8, 8, 8]_epo4_bs48_lr0.01_seed1234/epoch_3.pth
 75%|█████████████████████▊       | 3/4 [4:46:24<1:35:28, 5728.31s/it]
/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "/home/mhashemi/TransVNet/test.py", line 384, in <module>
    net.load_state_dict(torch.load(snapshot)) # Loading the parameters from the training results
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 2041, in load_state_dict
    raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
RuntimeError: Error(s) in loading state_dict for DataParallel:
	size mismatch for module.transformer.embeddings.position_embeddings: copying a param with shape torch.Size([1, 512, 768]) from checkpoint, the shape in current model is torch.Size([1, 64, 768]).
	size mismatch for module.transformer.embeddings.patch_embeddings.weight: copying a param with shape torch.Size([768, 3, 8, 8, 8]) from checkpoint, the shape in current model is torch.Size([768, 3, 16, 16, 16]).

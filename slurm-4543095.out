/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Namespace(dataset='Design', img_size=[64, 64, 64], vit_patches_size=[4, 4, 4], vit_name='Conv-ViT-Gen2-B_16', pretrained_net_path=False, is_encoder_pretrained=True, deterministic=1, max_epochs=100, batch_size=128, base_lr=0.01, seed=1234, gpu=4, world_size=-1, rank=-1, dist_url='env://', dist_backend='nccl', local_rank=-1, num_classes=2, root_path='/work/sheidaei/mhashemi/data/mat', list_dir='./lists/lists_Design', exp='TVG_Design[64, 64, 64]', distributed=False)
3 iterations per epoch. 300 max iterations 
  0%|                                         | 0/100 [00:00<?, ?it/s]  0%|                                         | 0/100 [01:42<?, ?it/s]
Traceback (most recent call last):
  File "/home/mhashemi/TransVNet/train.py", line 178, in <module>
    trainer[dataset_name](args, model, snapshot_path)
  File "/home/mhashemi/TransVNet/trainer.py", line 284, in trainer_mat
    predicted_labels, decoder_output, kl, log_pxz = model(image_batch, time_batch) # decoder_output is in fact the logits of the output image whose channels represent the categories/classes (each class = a material phase in this function)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 181, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 89, in parallel_apply
    output.reraise()
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
RuntimeError: Caught RuntimeError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mhashemi/TransVNet/networks/TransVNet_modeling.py", line 764, in forward
    mu, log_variance, predicted_labels = self.encoder(x, time)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mhashemi/TransVNet/networks/TransVNet_modeling.py", line 684, in forward
    x_encoded, attn_weights, features = self.transformer(x, time)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mhashemi/TransVNet/networks/TransVNet_modeling.py", line 332, in forward
    encoded, attn_weights = self.encoder(embedding_output)  # (B, n_patch, hidden)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mhashemi/TransVNet/networks/TransVNet_modeling.py", line 314, in forward
    hidden_states, weights = layer_block(hidden_states)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mhashemi/TransVNet/networks/TransVNet_modeling.py", line 254, in forward
    x, weights = self.attn(x)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/mhashemi/TransVNet/networks/TransVNet_modeling.py", line 99, in forward
    attention_output = self.out(context_layer)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (8192x252 and 256x256)

/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Traceback (most recent call last):
  File "/home/mhashemi/TransVNet/test.py", line 359, in <module>
    net.load_state_dict(torch.load(snapshot)) # Loading the parameters from the training results
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/serialization.py", line 791, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/serialization.py", line 271, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/work/sheidaei/conda/envs/mytorch/lib/python3.9/site-packages/torch/serialization.py", line 252, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '../model/TVG_Design[64, 64, 64]/TVG_encoderpretrained_Conv-ViT-Gen2-B_16_vitpatch[4, 4, 4]_epo100_bs128_lr0.01_seed1234/epoch_99.pth'
